Below is a **surgical, lineâ€‘level checklist** for dropping GPTâ€‘4oâ€‘Transcribe into your bot, keeping Gemini for summarising, and letting the user switch engines from the existing settings menu.

---

## 1â€¯Â·â€¯Add the dependency & key

1. **requirements.txt**

   ```text
   openai>=1.25.0        # new
   ```

   Then run `pip install -r requirements.txt`.

2. **Environment / hosting panel**

   ```
   export OPENAI_API_KEY=skâ€‘************************
   ```

3. **config.py** â€“ append:

   ```python
   OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
   if not OPENAI_API_KEY:
       print("OPENAI_API_KEY not set", file=sys.stderr); sys.exit(1)
   ```

---

## 2â€¯Â·â€¯Create *openai\_utils.py*

```python
# openai_utils.py
import os, logging, aiofiles
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def transcribe_gpt4o(audio_path: str, language: str = "ru") -> str | None:
    """Return plainâ€‘text transcript or None on error."""
    try:
        async with aiofiles.open(audio_path, "rb") as f:
            resp = await client.audio.transcriptions.create(
                file=await f.read(),
                model="gpt-4o-transcribe",
                language=language           # autoâ€‘detect if empty
            )
        return resp.text
    except Exception as e:
        logger.exception("GPTâ€‘4o transcription failed: %s", e)
        return None
```

*Accuracy & speed refs: OpenAI docs list gptâ€‘4oâ€‘transcribe as the current SOTA STT modelâ€¯([OpenAI Platform][1]); independent tests show \~9â€¯% WERâ€”30â€¯% better than Whisperâ€¯v3â€¯([VentureBeat][2]).*

---

## 3â€¯Â·â€¯DB: store the preferred STT engine

1. **Migration (once):**

   ```sql
   ALTER TABLE chat_preferences
   ADD COLUMN IF NOT EXISTS stt_engine TEXT DEFAULT 'gpt4o';
   ```

2. **db\_utils.py** â€“ helper wrappers

   ```python
   async def get_chat_stt_engine(pool, chat_id):
       rec = await pool.fetchrow("SELECT stt_engine FROM chat_preferences WHERE chat_id=$1", chat_id)
       return rec["stt_engine"] if rec else "gpt4o"

   async def set_chat_stt_engine(pool, chat_id, engine):
       await pool.execute("""
           INSERT INTO chat_preferences (chat_id, stt_engine)
                VALUES ($1,$2)
           ON CONFLICT (chat_id)
                DO UPDATE SET stt_engine = EXCLUDED.stt_engine, updated_at = NOW();
       """, chat_id, engine)
   ```

---

## 4â€¯Â·â€¯Let the user pick: extend the settings keyboard

### a) **bot.py** â€“ new button creator

```python
def create_stt_engine_buttons(chat_lang: str, current: str):
    gpt_label = "ğŸ™ï¸ GPTâ€‘4o" + (" âœ…" if current == "gpt4o" else "")
    gem_label = "ğŸ™ï¸ Gemini" + (" âœ…" if current == "gemini" else "")
    return InlineKeyboardMarkup([[
        InlineKeyboardButton(gpt_label, callback_data="stt:set:gpt4o"),
        InlineKeyboardButton(gem_label, callback_data="stt:set:gemini")
    ]])
```

### b) Hook it into the existing **settings** callback

Locate the current `settings:` callback handler; just before it returns the keyboard, append:

```python
stt_engine = await get_chat_stt_engine(pool, chat_id)
keyboard.inline_keyboard.append(  # add new row
    create_stt_engine_buttons(chat_lang, stt_engine).inline_keyboard[0]
)
```

### c) **CallbackQueryHandler** for updates

```python
async def handle_stt_choice(update: Update, context: CallbackContext):
    _, _, engine = update.callback_query.data.split(":")   # "stt:set:gpt4o"
    await set_chat_stt_engine(context.bot_data['db_pool'], update.effective_chat.id, engine)
    await update.callback_query.answer("Engine switched âœ”ï¸", show_alert=False)
    await update.callback_query.edit_reply_markup(
        reply_markup=create_stt_engine_buttons('ru', engine)   # language can be passed in
    )

application.add_handler(CallbackQueryHandler(handle_stt_choice, pattern=r"^stt:set:"))
```

---

## 5â€¯Â·â€¯Routing logic in **handle\_voice\_message**

Replace the **â€œPass to Geminiâ€** block with:

```python
# 2. Decide STT engine
stt_engine = await get_chat_stt_engine(pool, message.chat_id)

# 3. Transcribe
transcript_text = None
if stt_engine == "gpt4o":
    from openai_utils import transcribe_gpt4o
    transcript_text = await transcribe_gpt4o(temp_audio_file.name, chat_lang)

# fallback if GPTâ€‘4o failed or Gemini chosen
if transcript_text is None:
    summary_text, transcript_text = await process_audio_with_gemini(
        temp_audio_file.name, mode, chat_lang
    )
else:
    # Only summarise (fast) â€“ reuse Gemini for textâ€‘only summary
    from gemini_utils import summarise_text_with_gemini   # see next step
    summary_text = await summarise_text_with_gemini(transcript_text, mode, chat_lang)
```

---

## 6â€¯Â·â€¯Add a **textâ€‘only summariser** (tiny change in *gemini\_utils.py*)

Right after `process_audio_with_gemini`, drop in:

```python
async def summarise_text_with_gemini(transcript: str, mode: str, language: str='ru') -> str:
    model = genai.GenerativeModel(model_name="models/gemini-2.0-flash")
    prompt = build_summary_prompt(transcript, mode, language)  # you already have this logic
    resp = await model.generate_content(
        contents=[prompt],
        generation_config={"temperature": 0.3}
    )
    return resp.text.strip()
```

*(Reuse your existing `build_summary_prompt` or copy the fragment from `process_audio_with_gemini`.)*

---

## 7â€¯Â·â€¯Done â€“ quick test

```bash
python bot.py
# in Telegram:
#  /settings âœ tap ğŸ™ï¸ GPTâ€‘4o
#  send a voice message âœ should transcribe via GPTâ€‘4o and summarise via Gemini
#  switch back to ğŸ™ï¸ Gemini to force the legacy path
```

You now have:

* **GPTâ€‘4oâ€‘Transcribe** for bestâ€‘inâ€‘class accuracy (multilingual inc. Russian).
* **Gemini Flash** as automatic fallback and as a userâ€‘selectable option.
* One extra dependency and \~70 new lines of codeâ€”no other architecture changes.

